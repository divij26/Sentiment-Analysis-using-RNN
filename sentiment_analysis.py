# -*- coding: utf-8 -*-
"""Sentiment Analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o3iMDS6UtVLuEP2RlHtTPO30Mg1rhOA_
"""

from keras.datasets import imdb

((XT,YT), (Xt, Yt)) = imdb.load_data(num_words=10000)

word_idx = imdb.get_word_index()

idx_words = dict([value,key] for (key,value) in word_idx.items())

actual_review = ' '.join([idx_words.get(idx-3,'?') for idx in XT[0]])

from keras.preprocessing import sequence

X_train = sequence.pad_sequences(XT, maxlen=500)
X_test = sequence.pad_sequences(Xt, maxlen=500)

print(X_train.shape)

from tensorflow.keras.layers import Embedding, SimpleRNN, Dense
from tensorflow.keras.models import Sequential

model = Sequential()
model.add(Embedding(10000,10))
model.add(SimpleRNN(32))
model.add(Dense(1, activation='sigmoid'))
model.summary()

model.compile(optimizer='rmsprop', loss="binary_crossentropy", metrics=['acc'])

from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.callbacks import EarlyStopping

checkpoint = ModelCheckpoint("best_model.h5", monitor="val_loss", verbose=0, save_best_only=True, mode="auto", period=1)
earlystop = EarlyStopping(monitor="val_acc", patience=2)

hist = model.fit(X_train, YT, validation_split=0.2, epochs=10, batch_size=128, callbacks=[checkpoint, earlystop])

import matplotlib.pyplot as plt

acc = hist.history["acc"]
val_acc = hist.history['val_acc']

loss = hist.history["loss"]
val_loss = hist.history['val_loss']

epochs = range(1, len(loss)+1)

plt.title("Loss vs Epochs")
plt.plot(epochs, loss, label="Training Loss")
plt.plot(epochs, val_loss, label="Validation Loss")
plt.legend()
plt.show()

plt.title("Accuracy vs Epcohs")
plt.plot(epochs, acc, label="Training Accuracy")
plt.plot(epochs, val_acc, label="Validation Accuracy")
plt.legend()
plt.show()

#model.save("RNN.h5")

model.load_weights("best_model.h5")

model.evaluate(X_train, YT)

